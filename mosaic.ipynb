{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030b8f13-f16c-4594-8bbd-027acc821e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Load Calibration Parameters\n",
    "def load_calibration(calibration_file):\n",
    "    with np.load(calibration_file) as data:\n",
    "        camera_matrix = data['camera_matrix']\n",
    "        distortion_coeffs = data['dist_coeffs']\n",
    "    print('Calibration data loaded')\n",
    "    return camera_matrix, distortion_coeffs\n",
    "\n",
    "# Undistort Image\n",
    "def undistort_image(image, camera_matrix, dist_coeffs):\n",
    "    h, w = image.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeffs, (w, h), 1, (w, h))\n",
    "    undistorted_img = cv2.undistort(image, camera_matrix, dist_coeffs, None, newcameramtx)\n",
    "    print('Image undistorted')\n",
    "    return undistorted_img\n",
    "\n",
    "# Harris Corner Detection\n",
    "def harris_corner_detection(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    dst = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "    dst = cv2.dilate(dst, None)\n",
    "    image[dst > 0.01 * dst.max()] = [0, 0, 255]\n",
    "    print('Harris corners detected')\n",
    "    return image, dst\n",
    "\n",
    "# Match Features Between Images\n",
    "def match_features(image1, image2):\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(gray1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(gray2, None)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    matched_points1 = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
    "    matched_points2 = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
    "\n",
    "    print(f'Matched {len(matches)} features')\n",
    "    return matched_points1, matched_points2\n",
    "\n",
    "# Create Mosaic\n",
    "def create_mosaic(images, camera_matrix, dist_coeffs):\n",
    "    undistorted_images = [undistort_image(img, camera_matrix, dist_coeffs) for img in images]\n",
    "    mosaic = undistorted_images[0]\n",
    "\n",
    "    for i, img in enumerate(undistorted_images[1:], start=1):\n",
    "        print(f'Stitching image {i} into the mosaic')\n",
    "        \n",
    "        mosaic_corners_img, mosaic_corners = harris_corner_detection(mosaic)\n",
    "        image_corners_img, image_corners = harris_corner_detection(img)\n",
    "        \n",
    "        points1, points2 = match_features(mosaic, img)\n",
    "        \n",
    "        H, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "        img_warp = cv2.warpPerspective(mosaic, H, (mosaic.shape[1] + img.shape[1], mosaic.shape[0]))\n",
    "\n",
    "        alpha = 0.5\n",
    "        beta = 1.0 - alpha\n",
    "        blended_img = cv2.addWeighted(img_warp[:img.shape[0], :img.shape[1]], alpha, img, beta, 0.0)\n",
    "        \n",
    "        mosaic[:img.shape[0], :img.shape[1]] = blended_img\n",
    "        print(f'Image {i} stitched')\n",
    "\n",
    "    print('Mosaic created')\n",
    "    return mosaic\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    calibration_file = '/home/trevis/bwsi-uav/laboratory_2024/week_1_Hw/camera_calibration.npz'\n",
    "    camera_matrix, dist_coeffs = load_calibration(calibration_file)\n",
    "\n",
    "    image_folder = '/home/trevis/bwsi-uav/laboratory_2024/week_1_Hw/camera_calibration_photo_mosaic/International Village - 15 Percent Overlap/*.jpg'\n",
    "    image_files = sorted(glob.glob(image_folder))\n",
    "    images = [cv2.imread(file) for file in image_files]\n",
    "\n",
    "    if not images:\n",
    "        print(\"No images found in the specified folder.\")\n",
    "    else:\n",
    "        print(f'{len(images)} images loaded for stitching.')\n",
    "        mosaic_image = create_mosaic(images, camera_matrix, dist_coeffs)\n",
    "        np.savez('/home/trevis/bwsi-uav/laboratory_2024/week_1_Hw/camera_calibration_photo_mosaic/mosaic', mosaic_image)\n",
    "\n",
    "        cv2.imshow('Mosaic', mosaic_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.imwrite('/home/trevis/bwsi-uav/laboratory_2024/week_1_Hw/camera_calibration_photo_mosaic/mosaic_image.jpg', mosaic_image)\n",
    "        print('Mosaic saved and displayed')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888598be-60d9-40eb-8a0a-d26f29a82c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
